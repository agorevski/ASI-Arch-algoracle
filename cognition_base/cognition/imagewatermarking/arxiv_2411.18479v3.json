[
    {
        "DESIGN_INSIGHT": "### DESIGN_INSIGHT_HIGH: [Unified Cryptographic Syntax for GenAI Watermarking – Four-Key API Separating Detection, Decoding, and Attribution]\nThis work replaces ad-hoc watermark “detector-only” designs with a principled, cryptographic API that cleanly separates watermark generation from three distinct verification tasks. A generative model M is instrumented via a keyed generator WatermarkM_{gk} to produce x = WatermarkM_{gk}(m, π), with optional message m. Verification is decomposed into Detect_{dtk}(x) ∈ {true,false}, Decode_{dck}(x) → {0,1}^k, and Attribute_{ak}(x) ∈ {true,false}, each with its own key.\n\nThe key mechanism is architectural separation of concerns: detection keys dtk can be deployed widely for robust detection, while an independent attribution key ak supports unforgeable provenance proofs without sacrificing robustness of Detect. The framework formalizes core guarantees with precise games:\n- False positives are content-agnostic: for any fixed x, Pr_{dtk}[Detect_{dtk}(x)=true] ≤ ε.\n- Public, unforgeable attribution is captured by the attribution game\n  \\[\n  \\Pr_{gk,ak}\\big[x \\leftarrow A^{\\ Watermark^M_{gk}}(1^\\lambda, ak):\\ \\mathrm{Attribute}_{ak}(x)=\\text{true} \\land x \\notin Q\\big] \\le \\mathrm{negl}(\\lambda),\n  \\]\n  where Q is the set of verbatim watermarked generations observed by A.\n\nFundamentally different from prior single-key detectors, this syntax exposes and operationalizes the inherent tension between robustness and unforgeability: robust Detect should succeed under admissible edits, whereas unforgeable Attribute must reject even minimally altered forgeries. By allowing independent publication of ak (via digital signatures) while keeping gk private, the design enables public attribution without enabling forgeries, a capability not supported by earlier monolithic detectors.\n\n### DESIGN_INSIGHT_HIGH: [Quality Ladder for Imperceptibility – From Low Distortion to Distortion-Free to Undetectable with Formal Games]\nThe paper replaces heuristic “quality is unchanged” claims with a tiered set of cryptographic indistinguishability notions that precisely quantify imperceptibility for watermarking. At the weakest level, distortion measures total variation shift between unwatermarked and watermarked response distributions:\n\\[\n\\mathrm{Distortion} := \\max_{m,\\pi}\\ \\tfrac12 \\sum_{x\\in \\mathcal{R}} \\Big|\\Pr[M(\\pi)\\!\\to\\!x]-\\Pr_{gk}[ \\mathrm{Watermark}^M_{gk}(m,\\pi)\\!\\to\\!x]\\Big|.\n\\]\n\nDistortion-freeness strengthens this to a computational (or statistical) single-sample indistinguishability game: for any ppt distinguisher D and prompt π,\n\\[\n\\Big|\\Pr_{x\\leftarrow M(\\pi)}[D(1^\\lambda,x)=1]-\\Pr_{gk,\\,x\\leftarrow \\mathrm{Watermark}^M_{gk}(m,\\pi)}[D(1^\\lambda,x)=1]\\Big|\\le \\mathrm{negl}(\\lambda).\n\\]\nThis ensures no detectable bias in any single generation. The strongest notion, undetectability, upgrades from single-response to multi-response/adaptive indistinguishability by giving D oracle access and requiring\n\\[\n\\Pr\\!\\big[D^{M,M}(1^\\lambda)=1\\big]-\\Pr_{gk}\\!\\big[D^{M,\\ \\mathrm{Watermark}^M_{gk}}(1^\\lambda)=1\\big]\\le \\mathrm{negl}(\\lambda),\n\\]\neven under adaptive prompting and variable number of queries.\n\nThis quality ladder clarifies fundamental differences from prior work: token-level “low distortion” schemes can still bias multi-sample statistics; “distortion-free” guarantees preserve single draws but can fail across many generations; only “undetectable” schemes provably preserve all efficiently-computable quality metrics across arbitrary numbers of generations and preclude key-learning by efficient adversaries. The formalism is modality-agnostic and unifies text, image, audio, and video watermark quality guarantees under a single set of cryptographic tests.\n\n### DESIGN_INSIGHT_MEDIUM: [Channel-Parameterized Robustness with Entropy Preconditions – A Unified Detection/Decoding Guarantee]\nInstead of evaluating robustness with ad-hoc edit lists, this work introduces a general, channel-based robustness definition that models both benign post-processing and adaptive attacks. Let E be a (possibly key-aware) channel acting on content x and let P(M,π,x) encode an entropy/randomness precondition necessary for any watermark to be present. Robust detection and decoding are defined by\n\\[\n\\Pr_{gk,dtk}\\!\\Big[\\ x\\!\\leftarrow\\!\\mathrm{Watermark}^M_{gk}(\\pi),\\ x'\\!\\leftarrow\\!E(x):\\ \\mathrm{Detect}_{dtk}(x')=\\mathrm{false}\\ \\wedge\\ P(M,\\pi,x)=\\mathrm{true}\\ \\Big]\\le \\epsilon,\n\\]\n\\[\n\\Pr_{gk,dck}\\!\\Big[\\ x\\!\\leftarrow\\!\\mathrm{Watermark}^M_{gk}(m,\\pi),\\ x'\\!\\leftarrow\\!E(x):\\ \\mathrm{Decode}_{dck}(x')\\neq m\\ \\wedge\\ P(M,\\pi,x)=\\mathrm{true}\\ \\Big]\\le \\epsilon.\n\\]\n\nThe key mechanism is to parameterize robustness by (i) the admissible channel class E (e.g., “edit,” “regeneration,” or “downsampling” channels), (ii) the adversary’s knowledge (black/gray/white-box, verifier feedback), and (iii) an explicit entropy condition P that is necessary for any scheme to embed a signal without sacrificing distortion-freeness. This resolves impossibility pitfalls (no scheme is robust to all channels, especially input-independent ones) and separates robustness analysis from detector bias by keeping false-positive guarantees content-agnostic.\n\nUnlike prior work that intertwined robustness, detectability thresholds, and dataset-specific assumptions, this formulation yields a single, modality-agnostic contract that maps directly to threat models and evaluation: common attacks instantiate E (paraphrasing, diffusion denoising, cropping), while robustness guarantees are stated as probability bounds conditioned on P. This channel view cleanly interfaces with the four-key API and supports principled comparisons of schemes under matched attack surfaces.",
        "EXPERIMENTAL_TRIGGER_PATTERNS": "**Task_Performance_Signatures**:\n- Language modeling (lambada_openai, wikitext, ptb)\n  - Undetectable/distortion-free text watermarking (e.g., Gumbel-style, PRC-based): expect stable accuracy and perplexity within 0–1% of baseline on lambada_openai; wikitext/ptb PPL change ≤1%; no measurable loss in long-context completion when sequence entropy is sufficient.\n  - Green-Red watermarking (token biasing): expect negligible-to-small degradation proportional to bias δ; typical patterns are +1–3% PPL on wikitext/ptb and ≤2% accuracy drop on lambada_openai at moderate δ; degradation is more pronounced on very long sequences or deterministic prompts (low entropy).\n  - Contextual conditions: quality stability is strongest when prompts induce high-entropy continuations; degradation bands widen under low-entropy or constrained decoding.\n- Reading comprehension (squad_completion, squad_v2, narrativeqa)\n  - Undetectable/distortion-free schemes: scores remain competitive (≤1% variation vs. baseline EM/F1) because single- and multi-response distribution is preserved.\n  - Green-Red schemes: slight drops (≈1–2% EM/F1) at higher δ; negligible change at low δ; differences appear on multi-paragraph contexts where repeated k-grams increase biasing frequency.\n- Commonsense reasoning (hellaswag, piqa, social_iqa, commonsenseqa)\n  - Undetectable/PRC schemes: expect similar accuracy to baseline (≤1% delta) across tasks; robustness in detection does not trade off reasoning accuracy.\n  - Green-Red: accuracy stable at low δ; small declines (≤2%) may surface on tasks with short options (lower entropy), especially commonsenseqa/piqa.\n- Factual QA (arc_easy, arc_challenge, boolq, openbookqa)\n  - Undetectable/distortion-free: accuracy parity within 0–1%; no task-specific regressions.\n  - Green-Red: minor accuracy variance (±2%) depending on δ and decoding temperature; stronger effects for arc_challenge at low-entropy choices.\n- Context resolution (winogrande, winograd)\n  - Undetectable/distortion-free: unchanged accuracy; stable resolution under long-coreference spans.\n  - Green-Red: expect stable or slightly degraded performance (≤1.5%) if δ induces systematic token preference on pronoun candidates.\n- Image generation metrics (FID, CLIP Score, Inception Score, LPIPS)\n  - PRC watermark (latent diffusion): expect FID/CLIP/Inception parity across multi-image batches (≤0.5% relative change); diversity metrics remain stable due to per-generation pseudorandom quadrant sampling; message embedding does not alter aggregate scores.\n  - Gaussian Shading: single-image fidelity appears lossless; across many images, expect diversity reductions (e.g., slight FID increase and LPIPS diversity drop) when using a fixed quadrant; anticipate 1–3% relative deterioration on large batches.\n  - Tree-Ring and fine-tuning-based (Stable Signature): expect noticeable fidelity and diversity degradation on multi-image sets; FID/LPIPS shifts are apparent and increase with watermark strength.\n- Detection effectiveness (cross-modal)\n  - Properly tuned detectors achieve AUROC ≥0.95 at fixed FPR 0.1% for zero-bit watermark presence tests on clean outputs.\n  - Robust schemes (PRC for text/images; semantic-sentence watermarks) maintain useful TPR under edit/regeneration channels; expect graceful decay with perturbation rate rather than abrupt failure.\n- Efficiency expectations\n  - Logit-bias text watermarking (Green-Red, Gumbel-style): inference throughput impact ≤5%; detection runs in O(T) tokens; memory overhead negligible.\n  - Undetectable PRC (text/image): similar accuracy and throughput as baseline; detection adds linear-time decoding; robust decoding succeeds up to a constant fraction of substitutions/cropping.\n  - Latent inversion detectors (e.g., DDIM inversion for Tree-Ring): detection latency increases substantially; expect 2×–5× slower verification per image compared to lightweight decoders.\n\n**Architectural_Symptoms**:\n- Training characteristics\n  - No-training watermarks (logit-bias, undetectable PRC sampling): base model training curves unchanged; downstream task fine-tunes exhibit identical loss trajectories; “smoother convergence” and “reduced variance” are preserved relative to the unwatermarked model because watermarking is applied at generation.\n  - Fine-tune–based image watermarks (Stable Signature): additional training objective introduces a secondary loss; expect slower initial convergence and mild instability if signature loss weight is mis-set; monitoring shows increased variance early; may require learning-rate warmups to avoid divergence.\n  - Stability indicators: undetectable/distortion-free schemes show no NaN occurrences and are robust to decoding hyperparameter adjustments (temperature/top-p) as long as entropy thresholds are met; Green-Red remains stable across δ in moderate ranges, but very large δ values correlate with small accuracy drops and occasional sampling artifacts.\n- Runtime/memory behaviors\n  - Text watermark generation: identical memory footprint to baseline decoding; throughput patterns closely match baseline; constant-time overhead per step for PRF/hash calls; GPU utilization unchanged; no OOM at larger batch sizes.\n  - PRC detection (text/image): linear-time decoders; constant extra CPU/GPU memory; stable throughput with sequence length; supports batched verification without spikes in memory bandwidth.\n  - DDIM inversion detectors (Tree-Ring): higher GPU time and memory; profiler shows increased kernel launch counts and longer diffusion-step chains; detection throughput degrades with image resolution; more frequent OOM at large batches.\n  - Gaussian Shading (image): sampling time parity with baseline; memory scaling unchanged; across many generations with a fixed key, diversity-sensitive metrics drift (profilers show consistent speed, but evaluation pipelines report distributional clustering in latent space).\n- Profiling signatures\n  - Undetectable/distortion-free: quality metrics (e.g., MAUVE, Self-BLEU for text; FID/CLIP/LPIPS for images) remain within baseline confidence intervals across multiple generations; detector AUROC ≥0.95 at FPR 0.1%; false positives bounded uniformly over fixed content.\n  - Robustness channels: under edit attacks (token deletion/replacement, image noising/cropping), robust detectors show monotone TPR decay with perturbation rate; non-robust detectors show sharp drops even at low perturbations.\n  - Hardware-specific behaviors: GPU memory traces for watermark generation overlap baseline; CPU utilization increases slightly (≤5%) during verification due to hashing/decoding; inversion-based detectors show elevated GPU kernel time per sample.\n  - Baseline comparison: any consistent increase in perplexity (>3%), significant FID rise (>3%), or throughput drop (>10%) suggests misconfigured watermark strength (e.g., δ too large), incorrect entropy thresholds, or detector miscalibration.",
        "BACKGROUND": "Title: SoK: Watermarking for AI-Generated Content\n\nHistorical Technical Context:\nBefore the recent wave of GenAI, digital watermarking in multimedia largely relied on signal-processing pipelines and classical ML. Visible and invisible watermarks were embedded post hoc into images, audio, or video, often in frequency domains via DWT/DCT/DWT-DCT-SVD, or using encoder–decoder CNNs for robust extraction. In text, early techniques were format-, lexical-, or syntax-based and operated as post-processing over human or machine text. Parallelly, modern generative architectures emerged: Transformers for language (LLMs) and diffusion models for images/video/audio replaced earlier RNN/LSTM/GAN paradigms, enabling high-fidelity, human-like content.\n\nAs generative models improved, post-hoc detectors (zero-shot curvature-based, and supervised discriminators) initially exploited artifacts (e.g., hand rendering errors in images, stylometric cues in text). These signals diminished as models advanced, leading to poor generalization and high false positives on out-of-distribution (OOD) data. Simultaneously, the provenance community (e.g., C2PA) developed cryptographic provenance standards, while industry began embedding watermarks during generation (e.g., SynthID), and policymakers (EU AI Act; US EO 14110; CA SB 942) called for machine-readable markings.\n\nThe problem space evolved from simple AI-vs-human classification to trustworthy, provable identification, attribution, and resilience under adversarial editing, paraphrasing, and regeneration. In text, “green–red” token-biasing watermarks and Gumbel-based samplers appeared; for images, latent-space schemes (Tree-Rings, Gaussian Shading) and fine-tuned generator watermarking (Stable Signature) proliferated. The field lacked unified definitions connecting quality preservation, statistical/detectability guarantees, robustness to channels, and cryptographic unforgeability—motivating this SoK’s formalization.\n\nTechnical Limitations:\n- Post-hoc detection reliability and generalization: Prior detectors report empirical error floors around 10^{-3} FPR and degrade on OOD data; they lack distribution-free FPR guarantees and can be gamed by paraphrasing/regeneration. They provide no attribution granularity (model/user/version).\n- Quality–detectability trade-offs and distribution shift: Many in-generation watermarks bias token or latent distributions, harming multi-sample quality and diversity. Example: Tree-Ring modifies latent Fourier rings, shifting from N(0,I); green–red token biasing induces per-token distortion. Without formal distortion/undetectability, cumulative drift across generations is unbounded.\n- Robustness gaps under realistic channels: Evasion via edit noise, paraphrasing/summarization, diffusion-based denoising, and downsampling/cropping often removes signals. Robustness definitions were ad hoc; guarantees rarely quantify error under channels E with precise conditions on response entropy.\n- Attribution and forgery: Most schemes are forgeable without embedding-key knowledge requirements; attackers can construct content that triggers detectors (spoofing) or claim false attribution. Lack of unforgeable public attribution hinders safe, open verification.\n- Computational and scalability constraints: Some detectors require key search or inversion. Example: distortion-free Gumbel with key cycling increases detector time and FPR by a factor L (keys), i.e., O(LT) over text length T; image detection via DDIM inversion adds O(S) denoising steps per verification (S = diffusion steps), raising latency and compute costs. Storage/coordination burdens for provenance-only solutions remain high.\n- Impossibility and entropy constraints: Statistical undetectability is impossible; computational undetectability requires non-repeated PRF inputs and sufficient empirical entropy. Low-entropy prompts (near-deterministic outputs) limit embed capacity and provable FN bounds.\n\nPaper Concepts:\n- Watermarking Scheme Syntax: A generative model M maps a prompt π to a sample \\( x \\sim M(\\pi) \\). A watermarking generator with key gk produces \\( x \\sim \\mathrm{Watermark}^{M}_{gk}(\\pi) \\) or \\( \\mathrm{Watermark}^{M}_{gk}(m,\\pi) \\) for message \\( m \\in \\{0,1\\}^k \\). Verification algorithms are Detect\\(_{dtk}(x)\\in\\{\\mathrm{true},\\mathrm{false}\\}\\), Decode\\(_{dck}(x)\\in\\{0,1\\}^k\\), and Attribute\\(_{ak}(x)\\in\\{\\mathrm{true},\\mathrm{false}\\}\\).\n- Distortion: Statistical drift between original and watermarked distributions on responses \\( R \\). Formally,\n  \\( \\mathrm{dist} = \\displaystyle \\max_{m,\\pi} \\frac{1}{2}\\sum_{x\\in R} \\left| \\Pr[M(\\pi)\\!\\to\\!x] - \\Pr_{gk}[\\mathrm{Watermark}^{M}_{gk}(m,\\pi)\\!\\to\\!x] \\right|. \\)\n  Intuition: smaller distortion implies closer single-sample quality; cumulative effects may still appear across many samples.\n- Distortion-freeness: Computational version requires that for any PPT distinguisher D and prompt π,\n  \\( \\left| \\Pr_{x\\leftarrow M(\\pi)}[D(1^\\lambda,x)=1] - \\Pr_{gk,x\\leftarrow \\mathrm{Watermark}^{M}_{gk}(m,\\pi)}[D(1^\\lambda,x)=1] \\right| \\le \\mathrm{negl}(\\lambda). \\)\n  Statistical distortion-freeness holds against unbounded D. Intuition: a single generation is distribution-preserving; multi-generation correlations may still reveal bias unless keys are rotated or pseudorandomly varied.\n- Undetectability: Even with adaptive oracle access, distinguishing original from watermarked generation is computationally infeasible:\n  \\( \\Big| \\Pr[D^{M,M}(1^\\lambda)=1] - \\Pr_{gk}[D^{M,\\mathrm{Watermark}^{M}_{gk}}(1^\\lambda)=1] \\Big| \\le \\mathrm{negl}(\\lambda). \\)\n  Role: implies preservation of any efficiently-computable quality metric, including multi-sample diversity (e.g., FID/CLIP/Inception) and hinders key extraction by learning.\n- False Positive Rate (FPR): For any fixed content x, and random detection key dtk,\n  \\( \\Pr_{dtk}[\\mathrm{Detect}_{dtk}(x)=\\mathrm{true}] \\le \\varepsilon. \\)\n  This is distribution-free over natural content, ensuring interpretability and legal defensibility.\n- Robustness (to channels): For a channel \\( E \\) (edits, regeneration, compression) and property \\( P \\) capturing sufficient entropy/randomness,\n  Detection robustness: \\( \\Pr_{gk,dtk}\\left[ x\\!\\leftarrow\\!\\mathrm{Watermark}^{M}_{gk}(\\pi),\\, x'\\!\\leftarrow\\!E(x):\\, \\mathrm{Detect}_{dtk}(x')=\\mathrm{false} \\wedge P(M,\\pi,x)=\\mathrm{true} \\right] \\le \\epsilon. \\)\n  Decoding robustness analogously bounds \\( \\Pr[\\mathrm{Decode}_{dck}(x') \\neq m] \\).\n  Intuition: models practical survivability under realistic transformations; no scheme can be robust to all E (e.g., content-independent channels).\n- Unforgeability (for attribution): For any PPT adversary A with query access to the watermarked generator, let Q be the set of oracle outputs seen. Then\n  \\( \\Pr_{gk,ak}\\!\\left[ x\\!\\leftarrow\\!A^{\\mathrm{Watermark}^{M}_{gk}}(1^\\lambda,ak):\\, \\mathrm{Attribute}_{ak}(x)=\\mathrm{true} \\wedge x\\notin Q \\right] \\le \\mathrm{negl}(\\lambda). \\)\n  Intuition: prevents falsely attributing content to the model; supports public attribution via digital signatures while keeping detection and attribution separable (robustness vs. unforgeability).\n\nExperimental Context:\nThe SoK advocates a dual evaluation philosophy: (1) derive analytical bounds for FPR/FNR based on scheme statistics (e.g., z-tests for green–red token ratios; code-decoder error exponents for PRCs), and (2) complement with empirical tests under broad data and perturbation regimes to cover entropy variability and hardware/model nondeterminism.\n\nEvaluations emphasize generative settings across modalities:\n- Detection effectiveness: AUROC and operating points at stringent FPR (e.g., 0.1% or lower); where possible, compute closed-form thresholds; for practical deployment, report calibration stability across prompts and lengths.\n- Robustness: test three attack families—edit/noise channels (token deletions/substitutions; image transforms, adversarial perturbations), regeneration (paraphrasing/summarization; diffusion denoising/autoencoding), and downsampling (emoji/pineapple deletion; cropping). Measure post-attack TPR at fixed FPR and decoding accuracy for multi-bit schemes.\n- Quality preservation: for text, Perplexity, Distinct-n, Self-BLEU, MAUVE, LLM-as-a-judge win rates, and task metrics (BLEU/ROUGE/BERTScore/BARTScore; code Pass@k). For images/video/audio, FID, CLIP score, Inception/LPIPS, PSNR/SSIM for post-processing, and human preference studies. Multi-sample metrics diagnose diversity loss from correlated keys; undetectable schemes should match unwatermarked baselines across these metrics.\n- Efficiency and scalability: report detector complexity per sample—e.g., O(T) for token-statistic tests; O(LT) when searching over L keys; O(S) diffusion inversions for latent recovery; memory/runtime overheads; and throughput impacts on generation.\n\nOverall, the paper aims to establish a rigorous, property-driven framework—quality (distortion/undetectability), reliability (distribution-free FPR and provable FN under entropy), robustness (channel-aware), security (unforgeability/attribution), message capacity, and efficiency—that future watermark designs and policy mandates can target, measure, and trade off in a principled, modality-agnostic manner.",
        "ALGORITHMIC_INNOVATION": "Core_Algorithm:\n- Replace the standard latent sampling in diffusion image generators with pseudorandom error-correcting-code (PRC)–indexed “quadrant shading” during generation, and add a PRC decoder in detection after DDIM inversion. Concretely, at each generation the model samples a latent z from an isotropic Gaussian, selects a sign pattern s = EncPRC(gk, m) keyed by gk and message m, and maps z to the s-orthant before decoding; detection inverts the image to an initial latent and decodes the sign pattern with the PRC decoder.\n- Key computational steps: (1) derive a codeword s ∈ {±1}^d via a PRF-seeded PRC encoder, (2) transform latent by a diagonal sign matrix to enforce orthant membership, (3) run the standard diffusion decoder D to produce the image, (4) detect by DDIM inversion R to recover an estimate of the initial latent and decode with DecPRC; for zero-bit, compute a correlation score and threshold.\n- Fundamental change: instead of fixed or heuristic latent patterns, each generation uses a fresh pseudorandom, error-correcting codeword that both appears statistically indistinguishable from random (undetectability) and corrects a constant fraction of bit flips in detection (robustness). This modifies only the sampling stage before the diffusion decoder and the post-hoc detection step; the diffusion network architecture and weights remain unchanged.\n\nKey_Mechanism:\n- The key insight is symmetry of the Gaussian latent prior and decoder equivariance: mapping a latent to any orthant via a fixed sign matrix preserves the single-sample output distribution; choosing a fresh pseudorandom orthant per generation removes cross-sample correlations, yielding undetectability across batches. Pseudorandom error-correcting codes simultaneously ensure codewords are computationally indistinguishable from uniform and have large minimum distance, so small latent perturbations (bit/sign flips) are decodable.\n- As a result, the watermark is distortion-free per image, undetectable without keys over many images, robust to bounded edits after inversion to latent, and supports multi-bit messages via PRC encoding.\n\nMathematical_Formulation:\n- Let M be a latent diffusion generator with decoder D, latent dimension d, and initial noise z ∼ p(z) = 𝒩(0, I_d). A keyed PRC provides an encoder EncPRC: {0,1}^k → {±1}^d and a decoder DecPRC: {±1}^d → {0,1}^k ∪ {⊥}.\n- Generation (watermark embedding): given message m and generation key gk,\n\\[\ns = \\mathrm{EncPRC}(gk, m) \\in \\{\\pm 1\\}^d,\\quad S = \\mathrm{diag}(s),\\quad z' = S\\,|z|\\,,\n\\]\n\\[\nx = D(z')\\,.\n\\]\nAssumption A1 (decoder equivariance): for any diagonal S with ±1 entries, \\( D(S|z|) \\overset{d}{=} D(z) \\). Under A1, single-sample distortion is zero.\n- Detection (zero-bit or multi-bit): estimate initial latent by DDIM inversion R,\n\\[\n\\hat{z} = R(x),\\quad b = \\mathrm{sign}(\\hat{z})\\in\\{\\pm 1\\}^d,\\quad \\hat{m} = \\mathrm{DecPRC}(b)\\,.\n\\]\nZero-bit score with known s:\n\\[\n\\mathrm{score}(x) = \\frac{1}{d}\\, b^\\top s,\\quad \\text{Detect}(x) = \\mathbf{1}\\{\\,\\mathrm{score}(x) > \\tau\\,\\}\\,.\n\\]\nFor multi-bit, accept if \\( \\hat{m} \\neq \\bot \\).\n- Undetectability (computational): for any PPT distinguisher \\(D\\),\n\\[\n\\Big|\\Pr\\big[D^{M}(1^\\lambda)=1\\big] - \\Pr\\big[D^{M\\_w}(1^\\lambda)=1\\big]\\Big| \\leq \\mathrm{negl}(\\lambda)\\,,\n\\]\nwhere \\( M\\_w \\) uses fresh \\( s=\\mathrm{EncPRC}(gk,\\cdot) \\) per generation; pseudorandomness of PRC codewords and A1 imply equality in distribution under any efficient quality metric.\n- Robustness: model post-edit sign flips as a binary symmetric channel on b with flip rate q. If the PRC minimum relative distance \\( \\delta \\) and decoder radius \\( r \\) satisfy \\( q < r \\), then\n\\[\n\\Pr\\big[\\mathrm{DecPRC}(b)=m\\big] \\ge 1 - \\epsilon\\,,\n\\]\nfor some small \\( \\epsilon \\), and zero-bit detection obeys Chernoff-style FPR,\n\\[\n\\Pr[\\mathrm{score}(x)>\\tau \\mid b \\perp s] \\le \\exp(-d\\tau^2/2)\\,.\n\\]\n- Complexity: embedding adds \\( O(d) \\) elementwise ops; detection adds \\( O(Td) \\) for DDIM inversion with T steps plus \\( O(d) \\) for sign extraction and \\( O(d \\log d) \\) for PRC decoding (e.g., syndrome decoding).\n\nExample Format:\n- Attention score: \\( a_{st} = q_s^\\top k_t \\lambda^{s-t} \\exp(i\\theta(s-t)) \\)\n- State update: \\( s_i = s_{i-1} + \\phi(K_i) V_i^T \\), \\( z_i = z_{i-1} + \\phi(K_i) \\)\n- Complexity: O(nd²) vs. O(n²d) for standard attention\n\nComputational_Properties:\n- Time Complexity:\n  - Training: none; watermarking is training-free (no fine-tuning). The PRC construction is offline \\( O(d \\log d) \\) for generator/parity matrices; per-generation sampling remains dominated by the diffusion decoder.\n  - Inference (generation): \\( O(d) \\) extra for \\( z' = S|z| \\) (vector abs + elementwise multiply). Overall unchanged asymptotics w.r.t. decoder runtime.\n  - Detection: DDIM inversion \\( O(Td) \\) with T diffusion steps; sign extraction \\( O(d) \\); PRC decoding typically \\( O(d \\log d) \\) (syndrome/BP decoding) or \\( O(d) \\) for specialized constructions.\n- Space Complexity:\n  - Generation: negligible extra memory (store one codeword s, \\( O(d) \\), and key gk). No additional model parameters.\n  - Detection: store \\(\\hat{z}\\) and s (if zero-bit); PRC decoder state \\( O(d) \\).\n- Parallelization:\n  - Embedding and detection operations are embarrassingly parallel (elementwise abs/mul/sign); fit GPU vectorization well. DDIM inversion is identical to standard diffusion inference and benefits from existing GPU kernels and data-parallel batching. PRC decoding can be implemented with SIMD-friendly bit operations or GPU kernels for LDPC-like codes.\n- Hardware Compatibility:\n  - No changes to network topology or layer types; identical memory access patterns to standard diffusion sampling plus a single elementwise pass. Minimal bandwidth overhead (one extra pass over latent tensor). CPU-only detection feasible for small d; GPU recommended for fast inversion and batch verification.\n- Training vs. Inference:\n  - No training-time cost; purely inference-time watermarking. If the verifier runs offline, detection cost can be amortized by batching DDIM inversions.\n- Parameter Count:\n  - Zero new neural parameters. Keys and PRC matrices are non-neural artifacts; storage overhead \\( O(dk) \\) if persisting generator/parity matrices or PRF seeds.\n- Numerical Stability:\n  - Potential instability arises when latent coordinates are near zero (sign ambiguity). Mitigations: margin thresholding \\( b_i = \\mathrm{sign}(\\hat{z}_i) \\) with dead-zone \\( |\\hat{z}_i|>\\eta \\); reject/erasure marks for \\( |\\hat{z}_i|\\le \\eta \\) and use erasure-decoding in PRC. Inversion drift across steps can be reduced via consistent scheduler and teacher-forced inversion; robustness analysis remains valid with a bounded effective flip+erasure rate.\n- Scaling Behavior:\n  - As image resolution (and thus d) grows, detection becomes statistically stronger (FPR decays like \\( \\exp(-d\\tau^2/2) \\)), while robustness increases due to larger code distances at similar relative rates. Generation overhead remains linear in d and negligible w.r.t. decoder FLOPs. Batch undetectability persists because fresh pseudorandom orthants eliminate cross-sample correlations; throughput scales with standard diffusion batching.",
        "IMPLEMENTATION_GUIDANCE": "Integration_Strategy:\n- Text LLMs (generation-time integration):\n  - Hook into the token sampling path; in HuggingFace Transformers, add a custom LogitsProcessor to model.generate() that:\n    - Green-Red WM: computes G/R partition at each step via a PRF keyed by gk over the last k tokens; add +δ to logits[v∈G]. Replace/extend processors list with WatermarkLogitsProcessor(gk, k, δ, gamma).\n    - Gumbel/Distortion-free WM: replace softmax sampling with Gumbel-Max sampling whose Gumbel noise is derived from a keyed PRF sequence; optionally use a fixed key cycle for robustness. Implement as WatermarkGumbelSampler(gk, key_cycle_len=L). Disable temperature scaling after the Gumbel noise is added to preserve distribution.\n    - Undetectable WM (entropy-gated): insert EntropyGate before watermarking; accumulate empirical entropy Ĥ over tokens using model logits; only start biasing once Ĥ ≥ h_min. Implement as EntropyAwareWatermarkProcessor(gk, h_min, block_entropy=B, blockwise=True).\n    - PRC WM (robust+undetectable, research prototype): add a TokenCorrelationController that correlates token sequence with a PRC codeword chosen via a PRF keyed by gk; detector applies PRC decoding. Keep this modular as TokenPRCProcessor(gk, code_family, n, t) and integrate after logits but before softmax.\n  - Detection APIs:\n    - Green-Red: implement z_score(text, gamma) and a detector Detectdtk(x) comparing z to z_thresh(FPR). Provide both streaming and batch versions. Integrate as a Transformers Callback or standalone function.\n    - Gumbel cycle: brute-force over L key sequences; implement score aggregation and select max-likelihood key; cache results per document to amortize cost.\n    - Entropy-gated/Undetectable: detector requires knowledge of block boundaries (via entropy gate) or signature structure; implement block-level verification that at least one block decodes correctly; keep a separate Attributeak(x) for public attribution if using signature-based schemes.\n    - PRC: integrate an efficient PRC decoder (Rust/C++ with Python bindings via pybind11) for speed; expose Detectdtk(x) returning success flag and edit distance estimate.\n- Text frameworks compatibility:\n  - PyTorch: LogitsProcessor is native; maintain dtype fp16/bf16 compatibility; PRF implemented via HMAC-SHA256 or AES-CTR using torch.uint8 buffers; avoid autograd paths (generation is inference).\n  - TensorFlow/JAX: wrap sampling in a jit/compiled function; ensure PRF is XLA-compatible (prefer AES-CTR via jax.random.fold_in; or pure SHA256 in TF with tf.raw_ops).\n- Image diffusion models (latent-diffusion pipelines):\n  - Modify latent initialization z0 sampling in the scheduler/pipeline:\n    - Gaussian Shading: sample z0 ~ N(0,I), then project to a fixed quadrant determined by gk: z0 = sign_mask ⊙ |z0| with sign_mask ∈ {−1,+1}^d.\n    - PRC Watermark (preferred): derive a pseudorandom sequence of quadrants per generation via PRC codeword; each image uses a fresh quadrant assignment; implement in Diffusers by subclassing the Scheduler or overriding pipeline.prepare_latents().\n  - Detection:\n    - Use DDIM inversion (20–100 steps) to recover ẑ0; compute quadrant consistency score s = (1/d) Σ_i 1[sign(ẑ0,i) = sign_mask_i]; for PRC, pass s per block to the decoder.\n    - Integrate as a standalone detect_image(img, dtk) function using Diffusers inversion or custom denoiser; expose both GPU and CPU paths.\n- Migration path:\n  - From Green-Red to Undetectable/PRC: start with LogitsProcessor-based WM; add EntropyGate; later swap to PRC TokenCorrelationController. Keep detector interfaces stable (Detect/Decode/Attribute).\n  - From Gaussian Shading to PRC WM: replace fixed quadrant mask with PRC-selected masks; update detector to decode messages; maintain image generation API unchanged.\n- Dependencies:\n  - PRF: HMAC-SHA256 or AES-CTR (libsodium/pycryptodome). Favor AES-CTR for speed on CPU; for GPU, precompute PRF streams on CPU and upload as uint8 buffers.\n  - PRC decoder: C++/Rust library with SIMD (AVX2/AVX-512) acceleration; optional CUDA kernel for batched decoding.\n  - DDIM inversion: Diffusers >= 0.27.0; requires exact scheduler config used at generation.\n- Training pipeline integration:\n  - Stable Signature-style finetuning (if used): insert watermark extractor W and fine-tune decoder D; requires a 2-stage training loop. Not recommended where quality parity is critical; use in-processing latent WMs instead.\n  - No retraining needed for Green-Red, Gumbel, Entropy-gated, Gaussian Shading, and PRC latent WM—these are sampling-time only.\n\nParameter_Settings:\n- Text Green-Red WM:\n  - k (k-gram length): 2–5 (default 4). Larger k increases robustness but raises collision risk for short texts.\n  - gamma (green ratio): 0.5 ± 0.05 (default 0.5).\n  - δ (logit bias): 0.8–3.0; scale with temperature τ: use δ_eff = δ/τ. For τ ∈ [0.7,1.3], set δ ∈ [1.2,2.2].\n  - z_thresh for fixed FPR ε: one-sided normal quantile Φ^{-1}(1−ε). Examples: ε=10^-3 → z_thresh≈3.09; ε=10^-4 → 3.72; ε=10^-5 → 4.27.\n  - Token budget T: detection stabilizes at T ≥ 300 tokens; for ε ≤ 10^-3 target T ≥ 500; for ε ≤ 10^-5 target T ≥ 800.\n- Text Gumbel WM (distortion-free):\n  - L (key cycle length for robustness): 64–1024; detector FPR scales ≈ L×ε_base; choose L ≤ 256 when ε_base ≤ 10^-5.\n  - PRF entropy per step: 32–64 bits; initialize via HMAC-SHA256(key, context) mod range.\n- Undetectable WM (entropy-gated):\n  - h_min (start watermarking threshold): 8–16 bits cumulative empirical entropy; conservative default 12 bits.\n  - block_entropy B: 24–48 bits per block; larger B improves crop robustness with fewer blocks.\n  - Max blocks per document: 2–8; avoid dense watermarking to limit edit vulnerability.\n- Text PRC WM (prototype):\n  - Code parameters (n, t): n = 512–2048 tokens per codeword; t (edit/substitution tolerance) = 0.1–0.3 (fraction). Message length m_bits = 16–64 via code index.\n  - Decoder confidence threshold: 0.6–0.8 correlation score depending on n and t.\n- Image Gaussian Shading:\n  - d (latent dimensionality): inferred from model (e.g., 4×64×64 for SD v1 latent).\n  - Quadrant mask density α: 50% of dimensions constrained (default); range 25–75% for detector strength vs diversity trade-off.\n- Image PRC WM:\n  - Block size in latent space: 8×8–16×16 patches; per-block quadrant selection encodes bits.\n  - DDIM inversion steps: 20–50 for speed; 50–100 for stronger detection; η=0.0 (deterministic).\n  - Correlation threshold per block s_thresh: 0.55–0.7; global decode requires ≥q blocks passing (q = 60–80%).\n- Initialization:\n  - Keys: 128–256-bit gk/dtk/dck/ak via a CSPRNG; store in HSM or KMS.\n  - PRF: HMAC-SHA256 keyed with gk; seed per generation with UUIDv4 and prompt hash.\n- Critical vs robust parameters:\n  - Critical: z_thresh, ε target, δ_eff, h_min, PRC (n,t), DDIM steps. Tune carefully to meet FPR/TPR.\n  - Robust: k, gamma (near 0.5), block_entropy ranges, quadrant density α (image).\n- Scale-dependent settings:\n  - Small LLMs (<1B params): lower τ; use δ in 1.6–2.6; k=3; T ≥ 600 for reliable detection.\n  - Large LLMs (≥7B): δ in 1.2–2.0; k=4–5; entropy gates reach h_min faster.\n  - High-res diffusion (≥768px): increase DDIM steps to 50–80; per-block latent size 16×16.\n- Hardware-dependent:\n  - GPUs (A100/H100): run PRC decoder on CPU AVX-512; DDIM inversion on GPU fp16/bf16; batch size 8–32 images.\n  - Consumer GPUs (RTX 3090/4090, 24GB): DDIM inversion 20–40 steps; batch size 4–8; prefer CPU PRF streams.\n  - CPU-only detection: feasible for text (microseconds per doc); image inversion slow (2–10 s per 512×512 image at 50 steps).\n\nApplication_Conditions:\n- Beneficial scenarios:\n  - Text provenance at scale (moderation, training data filtering): Green-Red or Entropy-gated WM with ε ∈ [10^-3,10^-5], T ≥ 500.\n  - Public attribution (open verification): Signature-based undetectable WM with separate Attributeak, or PRC WM with published ak.\n  - Robustness to light edits (≤20% deletions/substitutions): Gumbel cycle (L≤256) or PRC WM (t≥0.2).\n  - Image generation where quality parity is mandatory: PRC latent WM; avoid Stable Signature-style finetuning.\n- Hardware requirements:\n  - Text: none beyond standard inference; memory footprint unchanged.\n  - Image: GPU recommended for inversion; minimum 12GB VRAM for 512×512; CPU-only acceptable for batch size 1 with 20–30 steps.\n- Scale considerations:\n  - Text WM becomes advantageous when documents are ≥300 tokens and false positives must be ≤10^-3.\n  - Image WM advantageous in high-throughput pipelines where retraining is infeasible; per-sample watermarking is O(1) overhead at sampling.\n- Task compatibility:\n  - Text: neutral for general generation; may be harmful for strictly deterministic outputs (e.g., exact code templates)—disable or reduce δ_eff.\n  - Image: neutral for standard sampling; harmful for tasks requiring distributional diversity across many images if using fixed quadrants—use PRC to vary quadrants per image.\n- Alternatives:\n  - If strict robustness to paraphrasing/summarization is required, consider semantic sentence WM (SemStamp/k-SemStamp); expect higher latency and lower throughput.\n  - If retraining is acceptable and detectable signature is desired, Stable Signature; expect quality trade-offs and vulnerability to regeneration attacks.\n- Resource constraints:\n  - Low-latency text services: use Entropy-gated watermarking (start watermark late); minimal overhead (<1%).\n  - Limited detector access or public verification: prefer unforgeable public attribution with digital signatures; publish ak only.\n\nExpected_Outcomes:\n- Detection performance (text):\n  - Green-Red at ε=10^-3: TPR 95–99% for T ∈ [500,1200]; at ε=10^-5: TPR 90–96% for T ≥ 800.\n  - Under edit attacks: deletions 10–20% → TPR drops by 5–20%; synonym substitutions 10–20% → drop 10–30%.\n  - Entropy-gated undetectable WM: identical single-response quality; robust to cropping with blockwise design; weak to token substitutions affecting the gated segment.\n  - PRC WM (prototype): maintains undetectability with TPR ≥ 90% up to t≈0.2 edit fraction; practical performance depends on decoder implementation.\n- Detection performance (image):\n  - Gaussian Shading: single-image quality parity; across many images diversity metrics can degrade; detection accuracy ≥ 95% under mild noise/compression.\n  - PRC latent WM: undetectable across generations (FID/CLIP differences < 1% vs baseline); detection TPR 92–98% with 50 inversion steps; resilient to JPEG 50–90, Gaussian noise σ ≤ 0.05, and mild crops (≤15%).\n- Timeline expectations:\n  - Generation-time watermarking yields immediate provenance benefits; detectors can be deployed concurrently.\n  - PRC decoder optimization may require 1–2 engineering sprints to reach low-latency targets.\n- Trade-offs:\n  - Increasing δ improves detectability but raises stylistic bias risk; entropy gating mitigates this at the cost of vulnerability to edits early in the document.\n  - Larger L (Gumbel cycle) strengthens robustness but inflates detector FPR by L×; balance L with ε.\n  - More inversion steps improve image detection but increase latency (e.g., 20→50 steps adds 1.5–2.5× runtime).\n- Benchmarks:\n  - Text: AUROC ≥ 0.98 at ε=10^-3 on diverse prompts for Green-Red; MAUVE change ≤ 5%; PPL increase ≤ 2%.\n  - Image: FID change ≤ 1% (PRC WM) vs baseline; SSIM/LPIPS within ±0.01; detection AUROC ≥ 0.97 under WAVE-like perturbations.\n- Failure modes:\n  - Short texts (T < 200) produce low z; detector unstable.\n  - Deterministic prompts or hard constraints (exact quoting) prevent watermark embedding unless distortion is allowed.\n  - Image inversion mismatch (different scheduler or cfg) yields false negatives; ensure exact config capture.\n  - Public attribution misuse: robust detector used as attribution may enable false blame after edits; separate Detect and Attribute.\n- Debugging indicators:\n  - Text: z-score distributions—non-watermarked near N(0,1); watermarked shifted by +μ; monitor drift. Entropy-gate logs should show h_min crossings and block boundaries.\n  - Image: quadrant consistency s histogram—bimodal separation for watermarked vs non-watermarked; inversion residual norms decreasing over steps.\n- Hardware-specific outcomes:\n  - A100/H100: image inversion ~80–150 ms per 512×512 image at 30–40 steps; batched PRC decoding < 5 ms per doc.\n  - RTX 3090/4090: inversion 200–400 ms per image at 40 steps; decoding ~1–3 ms per doc CPU.\n  - CPU-only: text detection sub-ms; image inversion 2–10 s per image (not recommended for high-throughput).\n\nQuality Requirements:\n- Validation:\n  - Calibrate z_thresh via held-out human text to meet ε target; verify empirical FPR ≤ ε over ≥10^5 samples.\n  - Run robustness suites: deletions/substitutions at {5,10,20,30}% and paraphrasing; report TPR curves.\n  - For images, test under JPEG {90,70,50}, Gaussian noise σ ∈ [0.01,0.1], resize/crop {5–20}% and regeneration via denoising models.\n- Troubleshooting:\n  - Excess false positives: reduce δ_eff, increase T, or raise z_thresh; verify PRF uniqueness and k selection.\n  - Low TPR: increase δ_eff or block_entropy B; for PRC, adjust (n,t) and decoder thresholds.\n  - Image false negatives: align inversion scheduler/steps to generation; ensure latent normalization and seed capture.\n- Limitations/Risks:\n  - Public detection may enable privacy risks (user IDs embedded); enforce policy controls, limit embedded metadata length (≤32 bits), and provide opt-out.\n  - Unforgeability incompatible with robustness if the same function is used; maintain separate Attributeak and Detectdtk with clear policies.\n- Dependencies and scale:\n  - Ensure reproducible seeds and configs are logged with C2PA-style provenance for image pipelines.\n  - Keys rotation: support efficient key replacement; maintain key versioning in metadata; rotate gk/dtk quarterly or upon suspected compromise."
    }
]