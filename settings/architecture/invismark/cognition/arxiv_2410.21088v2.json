[
    {
        "DESIGN_INSIGHT": "### DESIGN_INSIGHT_HIGH: [Nullspace-Decoupled Watermarking via Low-Rank PMP Jacobian in Diffusion Sampling]\nShallow Diffuse replaces seed-coupled watermarking (Tree-Ring/RingID) with mid-timestep injection that is mathematically decoupled from image synthesis. Instead of modifying the initial Gaussian seed \\(x_T\\), it injects a watermark at an intermediate timestep \\(t^\\*\\) where the posterior mean predictor (PMP) \\(f_{\\theta,t}(x_t)\\) is locally linear and its Jacobian \\(J_{\\theta,t}(x_t) = \\nabla_{x_t} f_{\\theta,t}(x_t)\\) is low rank.\n\nThe core mechanism is to choose \\(t^\\* \\in [0.2T, 0.7T]\\) (empirically \\(t^\\* \\approx 0.3T\\)) and inject \\(x^{W}_{t^\\*} = x_{t^\\*} + \\lambda \\Delta x\\) with \\(\\Delta x \\sim \\mathcal{U}(\\mathbb{S}^{d-1})\\). By local linearization,\n\\[\nf_{\\theta,t}(x_{t^\\*} + \\lambda \\Delta x) \\approx f_{\\theta,t}(x_{t^\\*}) + \\lambda J_{\\theta,t}(x_{t^\\*}) \\Delta x,\n\\]\nand because \\(\\mathrm{rank}(J_{\\theta,t^\\*}) = r_{t^\\*} \\ll d\\), a random \\(\\Delta x\\) has a large component in \\(\\mathrm{Null}(J_{\\theta,t^\\*})\\), yielding \\(J_{\\theta,t^\\*}\\Delta x \\approx 0\\) and thus \\(f_{\\theta,t}(x^{W}_{t^\\*}) \\approx f_{\\theta,t}(x_{t^\\*})\\). This decouples watermarking from synthesis: the watermark does not perturb the predicted data \\(x_0\\) yet remains present in the sampling residual.\n\nFundamental difference from prior work: Tree-Ring/RingID alter the low-frequency spectrum of \\(x_T\\), coupling watermark bits with the entire reverse trajectory and the seed distribution, which degrades consistency and precludes user-side post-hoc embedding. Here, watermark influence appears only in the second term of the DDIM update,\n\\[\nx_{t-1} \\approx \\underbrace{\\sqrt{\\alpha_{t-1}} f_{\\theta,t}(x_{t})}_{\\text{data term}} + \\underbrace{\\frac{\\sqrt{1-\\alpha_{t-1}}}{\\sqrt{1-\\alpha_t}}\\big(x_t - \\sqrt{\\alpha_t} f_{\\theta,t}(x_t)\\big)}_{\\text{residual term carrying } \\lambda \\Delta x},\n\\]\nso generation consistency is preserved while detection reads the residual. Provably, consistency obeys\n\\[\n\\| f_{\\theta,t}(x_t+\\lambda \\Delta x) - f_{\\theta,t}(x_t)\\|_2 \\le \\lambda L\\, h(r_t), \\quad h(r_t) = \\sqrt{\\frac{r_t}{d} + \\frac{18\\pi^3}{d-2}\\log(2r_t)},\n\\]\nwith probability \\(\\ge 1 - r_t^{-1}\\) (Theorem 1), and one-step DDIM inversion recovers the watermark with bounded error (Theorem 2) via the scheduler-dependent term \\(g(\\alpha_t,\\alpha_{t-1})\\). This yields a training-free, seed-independent architecture that supports both server-side and user-side watermarking.\n\n### DESIGN_INSIGHT_MEDIUM: [High-Frequency DFT Masking at Mid-Timestep for Invisible yet Robust Watermarks]\nThe paper replaces low-frequency seed perturbations with high-frequency masking of the mid-timestep latent, minimizing perceptual distortion while retaining robustness. The watermark is constructed in the Fourier domain at \\(t^\\*\\) using a circular high-frequency mask \\(M\\) and a multi-ring key \\(W\\), without zero-frequency shift, so energy is injected into bands that carry less perceptual weight.\n\nThe key mechanism is a masked replacement in the DFT of \\(x_{t^\\*}\\):\n\\[\n\\lambda \\Delta x := \\mathrm{DFT}^{-1}\\big( \\mathrm{DFT}(x_{t^\\*}) \\odot (1-M) + W \\odot M \\big) - x_{t^\\*},\n\\]\nwhere \\(M\\) selects high-frequency coefficients and \\(W\\) encodes bits through rotationally symmetric rings sampled from \\(\\mathcal{N}(0,1)\\). Injecting at \\(t^\\*\\) (closer to \\(x_0\\)) further reduces visible artifacts compared to modifying \\(x_T\\). This contrasts with Tree-Ring/RingID that operate on low-frequency spectra of the initial noise, which visibly biases generations and harms consistency.\n\nDetection computes a masked frequency-domain p-value:\n\\[\n\\eta = \\frac{\\mathrm{sum}(M)\\,\\|M \\odot W - M \\odot \\mathrm{DFT}(\\bar{x}^W_{t^\\*})\\|_F^2}{\\|M \\odot \\mathrm{DFT}(\\bar{x}^W_{t^\\*})\\|_F^2},\n\\]\nafter DDIM inversion \\(\\bar{x}^W_{t^\\*} = \\mathrm{DDIM\\text{-}Inv}(\\bar{x}^W_0, t^\\*)\\). The high-frequency design improves invisibility (PSNR/SSIM/LPIPS) while maintaining strong TPR@1%FPR across distortion, regeneration, and averaging attacks; multi-key support arises from non-overlapping masks \\(M_i\\) for users \\((i=1,\\dots,K)\\).\n\n### DESIGN_INSIGHT_MEDIUM: [Training-Free Unified Server/User Watermarking via DDIM/CFG and Low-Rank Timing Selection]\nShallow Diffuse unifies server-side and user-side watermarking without retraining by leveraging standard diffusion operators (DDIM, DDIM-Inv, CFG) and a principled choice of the embedding timestep \\(t^\\*\\) guided by the low-rank structure of \\(J_{\\theta,t}\\). It replaces bespoke training pipelines with a lightweight algorithmic wrapper around sampling and inversion.\n\nMechanism: In server mode, given \\(x_T \\sim \\mathcal{N}(0,I)\\) and prompt \\(c\\), compute \\(x_{t^\\*}=\\mathrm{CFG}(x_T,t^\\*,c)\\), inject \\(x^W_{t^\\*}\\), then sample \\(x^W_{0}=\\mathrm{DDIM}(x^W_{t^\\*},0,c)\\). In user mode, invert a generated image \\(x_0\\) via \\(x_{t^\\*}=\\mathrm{DDIM\\text{-}Inv}(x_0,t^\\*,\\varnothing)\\), inject \\(x^W_{t^\\*}\\), and resample \\(x^W_{0}=\\mathrm{DDIM}(x^W_{t^\\*},0,\\varnothing)\\). Detection consistently uses inversion to \\(t^\\*\\) and the masked p-value \\(\\eta\\). The extension to T2I uses classifier-free guidance \\(\\tilde{\\epsilon}_\\theta(xt,t,c)=(1-\\eta)\\epsilon_\\theta(xt,t,\\varnothing)+\\eta\\epsilon_\\theta(xt,t,c)\\) with unchanged watermark math.\n\nDifference from prior approaches: seed-dependent methods cannot support user-side post-hoc embedding; adversarial-optimization methods (e.g., ROBIN) require training and tuning. Here, the low-rank timing policy (empirically \\(t^\\* \\approx 0.3T\\)) balances consistency and detectability, aligning with theory (Theorems 1–2) and ablations showing the best trade-off before rank minima are offset by inversion error. The architecture delivers a practical, model-agnostic pipeline with negligible computational overhead beyond standard sampling/inversion steps.",
        "EXPERIMENTAL_TRIGGER_PATTERNS": "Task_Performance_Signatures:\n- Image generation quality and consistency (server scenario; Stable Diffusion 2-1-base; same seeds as baseline):\n  - Expect near-parity with non-watermarked baseline on quality: CLIP-Score ≈ 0.3669 (within ±0.0005 of SD w/o WM), FID ≈ 25.6 (within +0.1 of baseline 25.56).\n  - Expect substantially higher consistency vs seed-embedded watermarks: PSNR ≥ 35 dB (typical 35.5 dB), SSIM ≈ 0.96, LPIPS ≈ 0.02.\n  - Quantitative margin over seed-watermark baselines: +21 dB to +24 dB PSNR vs RingID/Gaussian Shading (which are ~14 dB and ~11 dB respectively).\n- Image generation consistency (user scenario; COCO and DiffusionDB):\n  - COCO: PSNR ≈ 32.1 dB, SSIM ≈ 0.84, LPIPS ≈ 0.05; within ≈ 1 dB of the DDIM inversion upper bound (32.28 dB).\n  - DiffusionDB: PSNR ≈ 33.1 dB, SSIM ≈ 0.89, LPIPS ≈ 0.03; within ≈ 0.35 dB of the DDIM inversion upper bound (33.42 dB).\n  - Visual inspection should show minimal perceptual differences; avoids low-frequency artifacts visible in Tree-Ring/RingID.\n- Watermark robustness (ROC metrics; TPR@1%FPR) with high-frequency circular mask and ring-key:\n  - Server scenario (average over groups): ≈ 0.93 TPR@1%FPR; AUC ≈ 0.99.\n    - Distortion attacks (JPEG, blur, noise, color jitter, resize/restore, random drop, median blur): TPR@1%FPR ≈ 1.00 across all; AUC ≈ 1.00.\n    - Regeneration (DiffPure, VAE compressions, diffusion regeneration, Rinse 2×/4×): TPR@1%FPR ≈ 0.98 average (e.g., DiffPure/IC1/IC2/IR ~0.99–1.00; Rinse4× ~0.90).\n    - Adversarial averaging (black-box/grey-box): TPR@1%FPR ≈ 0.54 average (BB ~0.45, GB ~0.63).\n  - User scenario:\n    - COCO average: ≈ 0.93; Distortion: ≈ 1.00; Regeneration: ≈ 0.96; Adversarial averaging: ≈ 0.62.\n    - DiffusionDB average: ≈ 0.92; Distortion: ≈ 1.00; Regeneration: ≈ 0.93; Adversarial averaging: ≈ 0.59.\n- Trade-off curve (mask radius controls λ):\n  - Expect Shallow Diffuse to dominate RingID/Tree-Ring in PSNR/SSIM/LPIPS at matched robustness (its curve lies above theirs). As radius increases:\n    - Robustness rises to near 1.00 TPR@1%FPR; PSNR drops smoothly from ≈ 38 dB toward ≈ low 30s.\n- Timestep dependence (embedding at t*):\n  - Consistency peaks at t ≈ 0.2T; robustness peaks at t ≈ 0.3T. Recommended t* = 0.3T for best overall trade-off.\n  - Degradation bounds: for t → T (seed level), expect visible inconsistency and convergence toward Tree-Ring behavior; for t → 0, watermark detectability drops.\n- Channel and frequency placement:\n  - High-frequency band (DFT without zero-centering) with circular mask and rotationally constant ring-key yields:\n    - Best consistency (PSNR ≈ 38 dB at lighter λ) with AUC/TPR ≈ 1.00 in clean and distortion settings.\n  - Embedding across all latent channels (0+1+2+3) slightly degrades PSNR (≈ −3 dB) and robustness under strong color jitter; prefer single channel (e.g., channel 3).\n- Inference steps sensitivity:\n  - With 10/25/50 DDIM steps, robustness is stable (AUC ≈ 0.94–1.00 for non-adversarial, ≈ 0.94 for overall average); choose 25–50 steps for maximal parity with baseline image quality.\n- Multi-key watermarking (non-overlapping masks per key; concentric ring keys):\n  - Robustness remains high up to 8 keys (clean TPR@1%FPR ≈ 1.00; distortions/regeneration ≥ 0.70–0.99). Starts to decline at 16–32 keys, especially under regeneration/adversarial averaging; expect ≥ 0.44–0.56 average TPR at 32 keys with stronger degradations on hard attacks.\n- Expected neutrality on language and textual reasoning benchmarks (technique operates on image diffusion latents):\n  - lambada_openai, wikitext, ptb, squad_completion, squad_v2, narrativeqa, hellaswag, piqa, social_iqa, commonsenseqa, arc_easy, arc_challenge, boolq, openbookqa, winogrande, winograd, swde, fda:\n    - Expect no measurable effect; performance remains unchanged within typical run-to-run variance (≤ ±0.1–0.2% absolute) as the method is image-only and training-free.\n\nArchitectural_Symptoms:\n- Training characteristics:\n  - Training-free method; no optimizer states, no parameter updates, no training loss curves.\n  - Stability indicators: absence of NaNs/inf during embedding/detection; deterministic behavior given same seed and watermark key.\n- Runtime/inference behaviors:\n  - Memory profile comparable to standard DDIM sampling/inversion (no backprop); additional buffers for DFT/IDFT and mask/key (< a few MB per image), negligible vs model activations.\n  - Throughput patterns:\n    - Server-side: same sampling steps as baseline; added O(N log N) DFT/IDFT per image at the chosen timestep; negligible wall-clock overhead relative to UNet passes.\n    - User-side detection: one DDIM inversion pass to t* plus a DFT; runtime roughly one extra partial sampling cycle vs baseline verification-free usage.\n  - No OOM at batch sizes that fit standard Stable Diffusion inference; GPU utilization mirrors baseline UNet inference; bandwidth spikes correspond to single DFT/IDFT calls.\n- Profiling signatures indicating correct operation:\n  - DDIM inversion round-trip integrity (SD w/o WM upper bound): for user scenario, PSNR of round-trip baseline ≈ 32–33 dB; Shallow Diffuse should be within ≈ 0.1–1.0 dB of this ceiling.\n  - P-value η distribution separation (Eq. 7):\n    - Watermarked images: η clusters near 0 (often < 1e-3) even under distortions; non-watermarked: η significantly larger; clear threshold exists to achieve ~1% FPR with high TPR.\n    - Under adversarial averaging, η separation narrows; expect TPR drops to ~0.5–0.65 at 1% FPR (server/user).\n  - Rank/linearity sweet-spot at t*:\n    - Maximum consistency/robustness observed when t* in [0.2T, 0.3T]; moving t* toward T increases inconsistency (PSNR and SSIM drop, LPIPS rises) while raising robustness; toward 0 decreases robustness.\n  - Frequency localization:\n    - High-frequency placement yields minimal perceptual deltas; low-frequency masks show visible artifacts and reduced PSNR; if artifacts appear, verify mask centering (no shift) and ring-key configuration.\n  - Trade-off controllability:\n    - Increasing mask radius monotonically increases TPR and monotonically reduces PSNR/SSIM; curves should be smooth and superior to Tree-Ring/RingID at matched TPR.\n- Robustness signature across attack families:\n  - Distortions: detection nearly saturates (AUC≈1.00, TPR@1%FPR≈1.00); any significant drop suggests incorrect mask frequency band or channel setting.\n  - Regeneration: mild-to-moderate drops; Rinse4× is the most challenging; if large drops occur across all regeneration methods, verify t* and inversion step counts.\n  - Adversarial averaging: partial degradation expected; if TPR falls below ~0.4 at 1% FPR in server scenario, re-check watermark intensity (λ via mask radius) and ensure non-overlapping multi-key masks.\n- Scaling properties and limits:\n  - Multi-key capacity degrades beyond 8–16 keys with non-overlapping masks; symptoms include per-key TPR dispersion and increased cross-key false positives if masks overlap.\n  - Steps invariance: 10 vs 25 vs 50 steps show similar robustness; if robustness varies sharply with steps, check DDIM-Inv/operator settings (scheduler αt and prompt conditioning for user scenario should use ∅).\n- Comparison with baseline implementations:\n  - Relative to Tree-Ring/RingID:\n    - Expect much higher PSNR/SSIM and lower LPIPS at similar TPR; if not observed, embedding may be at incorrect timestep or mask placed in low-frequency region.\n  - Relative to Stable Signature/non-diffusion methods:\n    - Similar or better robustness without training; if robustness under distortions is < 0.95 TPR@1%FPR, confirm frequency mask radius and ring-key parameters.",
        "BACKGROUND": "Title: Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models\n\nHistorical Technical Context:\n- Before the rise of diffusion models, deep generative modeling was dominated by VAEs and GANs. VAEs optimized a variational lower bound to learn latent generative distributions, while GANs trained adversarial generator–discriminator pairs, achieving strong image realism but suffering from mode collapse and instability. CNNs provided the backbone feature extractors for images, and Transformers later enabled scalable text-to-image conditioning via cross-attention. The diffusion family (DDPMs/Score-based models; DDIM sampling) emerged as a robust alternative, defining a forward noising process and a learned reverse denoising process, with controllability improvements such as classifier-free guidance (CFG).\n- Digital watermarking historically operated in the frequency domain using DWT/DCT/SVD-based techniques to embed imperceptible signals into images. Learning-based watermarking (e.g., RivaGAN, StegaStamp) increased robustness and payload but required model training/fine-tuning for each watermark and often incurred computational overhead. As diffusion models became prevalent in content creation (Stable Diffusion, DALL·E, Imagen), diffusion-native watermarking approaches appeared: Stable Signature positioned marks in latent space; Tree-Ring and RingID injected structured Fourier patterns into the initial noise (seed) to enable server-side attribution; Gaussian Shading proposed provably lossless embedding but primarily for server-side generation.\n- These server-side approaches tightly coupled watermarking with the entire sampling trajectory and typically required access to the initial random seed, limiting applicability to user-side scenarios (post hoc watermarking of already generated images). At the same time, recent theoretical and empirical studies showed that diffusion models’ posterior mean predictor (PMP) exhibits local linearity and that its Jacobian is low rank over a wide range of timesteps, indicating that the generation process evolves within an intrinsic low-dimensional subspace. This motivates watermark designs that exploit null spaces to decouple watermark injection from the image formation dynamics.\n\nTechnical Limitations:\n- Seed-dependent coupling and inconsistency: Seed watermarks (Tree-Ring, RingID) perturb the Gaussian noise distribution at t = T, coupling watermark signals with subsequent denoising steps. This often yields inconsistent outputs across different watermark realizations due to distortion of the initial noise manifold and altered sampling trajectories.\n- Scenario constraints and memory/state access: Server-only methods require access to the initial seed x_T and generation metadata, rendering them unusable for user-side attribution. They also impose storage/retention burdens for seeds and generation logs in production systems.\n- Visual artifacts from low-frequency watermarking: Modifying low-frequency bands (high-energy components) can introduce perceptible distortions, degrading SSIM/LPIPS and content fidelity; this is exacerbated when applied near clean-image timesteps.\n- Robustness–consistency trade-off without guarantees: Prior approaches lacked provable bounds linking watermark detectability to generation consistency. Under common attacks (JPEG, blurring, color jitter, stochastic regeneration), detection could fail or require aggressive watermark strengths that hurt image quality.\n- Training/optimization overhead: Methods that rely on adversarial optimization or fine-tuning (e.g., ROBIN, deep watermarking) incur significant computational cost and complexity. In contrast, practical deployments demand training-free, single-pass embedding/detection with predictable overhead: injection O(d log d) via FFT/DFT and detection O(K·C_θ + d log d), where K is the number of DDIM-inversion steps and C_θ the per-step model cost.\n- Detection brittleness and scalability: Multi-key identification and robustness under grey/black-box averaging attacks are challenging. Seed-based ring methods can be defeated or become unstable when scaling to many keys; detector thresholds lack principled calibration against timesteps and rank statistics.\n\nPaper Concepts:\n- Posterior Mean Predictor (PMP): The deterministic component predicting the posterior mean at timestep t. In DDIM, one step may be written as\n  \\[\n  x_{t-1}=\\sqrt{\\alpha_{t-1}}\\Big(x_t-\\sqrt{1-\\alpha_t}\\,\\epsilon_\\theta(x_t,t)\\Big)/\\sqrt{\\alpha_t}\n  \\quad\\text{with}\\quad\n  f_{\\theta,t}(x_t):=\\sqrt{\\alpha_{t-1}}\\Big(x_t-\\sqrt{1-\\alpha_t}\\,\\epsilon_\\theta(x_t,t)\\Big)/\\sqrt{\\alpha_t}.\n  \\]\n  Locally linear near x_t, its first-order Taylor approximation is\n  \\[\n  f_{\\theta,t}(x_t+\\lambda\\Delta x)\\approx f_{\\theta,t}(x_t) + \\lambda J_{\\theta,t}(x_t)\\Delta x,\n  \\]\n  where \\(J_{\\theta,t}(x_t)=\\nabla_{x_t} f_{\\theta,t}(x_t)\\). Intuition: within a band of timesteps, PMP acts like a linear projector onto an intrinsic subspace governing image formation.\n- Low-Rank Jacobian and Null-Space Embedding: Empirically, \\(J_{\\theta,t}\\in\\mathbb{R}^{d\\times d}\\) exhibits very low numerical rank \\(r_t\\ll d\\) for \\(t\\in[0.2T,0.7T]\\). Let \\(\\mathcal{N}(J_{\\theta,t})\\) denote its null space. For a random \\(\\Delta x\\sim\\mathcal{U}(\\mathbb{S}^{d-1})\\), a large component lies in \\(\\mathcal{N}(J_{\\theta,t})\\), so \\(J_{\\theta,t}\\Delta x\\approx 0\\). Shallow Diffuse chooses a mid-timestep \\(t^\\*\\) to inject a watermark \\(\\lambda\\Delta x\\) so that\n  \\[\n  f_{\\theta,t^\\*}(x_{t^\\*}+\\lambda\\Delta x)\\approx f_{\\theta,t^\\*}(x_{t^\\*}),\n  \\]\n  decoupling watermark injection from the image prediction dynamics.\n- DDIM and DDIM Inversion: Deterministic sampling/inversion operators between timesteps. For \\(t_2>t_1\\),\n  \\[\n  x_{t_1}=\\mathrm{DDIM}(x_{t_2},t_1),\\qquad x_{t_2}=\\mathrm{DDIM\\mbox{-}Inv}(x_{t_1},t_2).\n  \\]\n  In T2I with CFG, replace \\(\\epsilon_\\theta(x_t,t)\\) by \\(\\tilde\\epsilon_\\theta(x_t,t,c)=(1-\\eta)\\epsilon_\\theta(x_t,t,\\varnothing)+\\eta\\epsilon_\\theta(x_t,t,c)\\). Complexity: O(K·C_θ) per trajectory (K steps), with shallow injection at a single midpoint step adding negligible overhead.\n- Frequency-Domain Mask–Key Watermark:\n  \\[\n  \\lambda\\Delta x := \\mathrm{DFT}^{-1}\\!\\big(\\mathrm{DFT}(x_{t^\\*})\\odot(1-M) + W\\odot M\\big) - x_{t^\\*}.\n  \\]\n  Here \\(M\\) is a circular mask (radius ≈ 8) selecting high-frequency bands (implemented by using unshifted DFT so the DC component is not centered), and \\(W\\) is a multi-ring key where each ring’s value is drawn i.i.d. from \\(\\mathcal{N}(0,1)\\). Intuition: high-frequency bands have lower energy and yield lower perceptual distortion, especially near clean-image timesteps; multi-ring structure enables multi-key identification.\n- Shallow Diffuse Injection and Decoupling:\n  - User scenario: \\(x_{t^\\*}=\\mathrm{DDIM\\mbox{-}Inv}(x_0,t^\\*)\\), then \\(x^W_{t^\\*}=x_{t^\\*}+\\lambda\\Delta x\\), and \\(x^W_0=\\mathrm{DDIM}(x^W_{t^\\*},0)\\).\n  - Server scenario: \\(x_{t^\\*}=\\mathrm{DDIM}(x_T,t^\\*)\\), same injection, then sample forward. The watermark propagates through the second term of DDIM, leaving the PMP term (image semantics) nearly unchanged due to \\(J_{\\theta,t^\\*}\\) low rank.\n- Fourier-Domain Detector:\n  \\[\n  \\eta=\\frac{\\mathrm{sum}(M)\\;\\big\\|M\\odot W-M\\odot \\mathrm{DFT}(\\bar x^W_{t^\\*})\\big\\|_F^2}{\\big\\|M\\odot \\mathrm{DFT}(\\bar x^W_{t^\\*})\\big\\|_F^2},\n  \\quad \\bar x^W_{t^\\*}=\\mathrm{DDIM\\mbox{-}Inv}(\\bar x^W_0,t^\\*).\n  \\]\n  Thresholding \\(\\eta\\) yields ROC curves; \\(\\eta\\approx 0\\) for correctly watermarked images. Intuition: masked high-frequency rings can be recovered after attacks because injection was decoupled from semantic prediction and concentrated outside the intrinsic subspace.\n- Provable Consistency and Detectability:\n  - Consistency (Theorem 1): with probability ≥ \\(1-r_t^{-1}\\),\n    \\[\n    \\big\\|\\hat x^{W}_{0,t}-\\hat x_{0,t}\\big\\|_2 \\le \\lambda L\\,h(r_t),\\quad\n    h(r_t)=\\sqrt{\\frac{r_t}{d}+\\frac{18\\pi^3}{d-2}\\log(2r_t)}.\n    \\]\n    Here \\(L\\) bounds \\(\\|J_{\\theta,t}\\|_2\\). Since \\(r_t\\ll d\\), the bound is small, explaining high PSNR/SSIM and low LPIPS.\n  - Detectability (Theorem 2): with probability ≥ \\(1-r_t^{-1}-r_{t-1}^{-1}\\),\n    \\[\n    \\big\\|\\bar x^W_t-x^W_t\\big\\|_2 \\le \\lambda L h(\\max\\{r_{t-1},r_t\\})\\Big[-g(\\alpha_t,\\alpha_{t-1})+g(\\alpha_{t-1},\\alpha_t)\\big(1-L\\,g(\\alpha_t,\\alpha_{t-1})\\big)\\Big],\n    \\]\n    where \\(g(x,y)=\\frac{\\sqrt{1-y}\\sqrt{x}-\\sqrt{1-x}\\sqrt{y}}{\\sqrt{1-x}}\\). For typical VP schedules, the bracketed term is small, ensuring reliable watermark recovery after one-step inversion.\n\nExperimental Context:\n- Evaluation tasks emphasize generative fidelity and watermark attribution under two deployment scenarios:\n  - Server-side: watermark embedded during sampling from \\(x_T\\).\n  - User-side: watermark injected post-generation via DDIM inversion from \\(x_0\\).\n  The study uses Stable Diffusion 2-1-base in latent space and extensive corruption/regeneration attacks to assess robustness.\n- Metrics and benchmarks: Consistency is quantified by PSNR, SSIM, and LPIPS against the original image. Generation quality in server-side is measured via CLIP-Score and FID. Robustness is reported using ROC AUC and TPR@1%FPR under 15 attacks spanning distortion (JPEG, Gaussian blur/noise, color jitter, resize–restore, random drop, median blur), regeneration (diffusion purification, VAE compressions, diffusion-based regeneration, multi-round “rinsing”), and adversarial averaging (black-box, grey-box).\n- Experimental goals: Demonstrate that mid-timestep, high-frequency mask–key watermarking achieves near-unchanged generative semantics (decoupling) with strong detectability under realistic attacks, and that the method is training-free, flexible across server/user settings, and supported by theory.\n- Representative results: In server-side (5000 images), Shallow Diffuse attains CLIP-Score 0.3669 and FID 25.60 (best among diffusion-based baselines), with PSNR 35.49, SSIM 0.96, LPIPS 0.02, and average TPR@1%FPR 0.93. In user-side (COCO, DiffusionDB; 500 images each), it achieves PSNR 32.11/33.07, SSIM 0.84/0.89, LPIPS 0.05/0.03, and average TPR@1%FPR 0.93/0.92, outperforming diffusion baselines on consistency while matching robustness of RingID/Gaussian Shading. Trade-off analyses show the Shallow Diffuse curve strictly dominates Tree-Ring and RingID (higher consistency for the same robustness). Ablations validate the choice \\(t^\\*\\approx 0.3T\\), high-frequency masking (unshifted DFT), single-channel embedding (c=3), and robustness across 10/25/50 DDIM steps. Multi-key experiments show strong clean robustness up to 32 keys, with adversarial robustness decreasing when keys exceed ≈16, highlighting a practical scaling frontier.",
        "ALGORITHMIC_INNOVATION": "Core_Algorithm:\n- Replace seed-level watermark embedding with shallow-timestep embedding: inject a watermark at an intermediate diffusion step t* (e.g., t* ≈ 0.3T) instead of modifying the initial Gaussian seed x_T. Operate in the latent space of the diffusion model.\n- Compute the watermark perturbation Δx in the frequency domain using a high-frequency circular mask M and a multi-ring Gaussian key W, then add it to the noisy latent x_{t*}. This results in x^{W}_{t*} = x_{t*} + λΔx, where λ controls watermark strength.\n- Decouple watermarking from image synthesis by exploiting the local linearity and low rank of the posterior mean predictor (PMP) f_θ,t; most of Δx lies in the null space of the Jacobian J_θ,t, so f_θ,t(x^{W}_{t*}) ≈ f_θ,t(x_{t*}). The watermark propagates only through the non-PMP term in DDIM, preserving image content.\n- Detect by performing DDIM inversion from the (possibly attacked) image to t*, transforming to frequency space, and computing a normalized residual score η between the masked spectrum and the stored key W. Works in both server (during sampling via CFG/DDIM) and user (post-hoc via DDIM inversion) scenarios.\n\nKey_Mechanism:\n- The key insight is that at mid-range timesteps the PMP’s Jacobian J_θ,t is numerically low rank and f_θ,t is locally linear. A random, spread-spectrum watermark vector Δx has a large component in the null space of J_θ,t, yielding J_θ,tΔx ≈ 0 and leaving the predicted x_0 unchanged.\n- Under DDIM, the watermark influences only the stochastic residual term while the PMP term stays intact, improving perceptual consistency. High-frequency spectral embedding further reduces visual distortion while remaining recoverable after common attacks.\n- Theoretical bounds (consistency and detectability) follow from Lipschitz continuity of f_θ,t and concentration on the sphere, quantifying small prediction drift and recoverability probability.\n\nMathematical_Formulation:\n- DDIM one-step update and PMP:\n  \\[\n  x_{t-1} = \\sqrt{\\alpha_{t-1}}\\, f_{\\theta,t}(x_t) + \\sqrt{1-\\alpha_{t-1}}\\;\\epsilon_\\theta(x_t,t),\\quad\n  f_{\\theta,t}(x_t) \\approx \\mathbb{E}[x_0 \\mid x_t]\n  \\]\n  With PMP and local linearization:\n  \\[\n  f_{\\theta,t}(x_t + \\lambda \\Delta x) \\approx f_{\\theta,t}(x_t) + \\lambda J_{\\theta,t}(x_t)\\Delta x\n  \\]\n- Watermark injection at shallow timestep t*:\n  \\[\n  x^{W}_{t^*} = x_{t^*} + \\lambda \\Delta x,\\quad\n  \\Delta x := \\mathrm{DFT}^{-1}\\!\\big(\\mathrm{DFT}(x_{t^*})\\odot(1-M) + W\\odot M\\big) - x_{t^*}\n  \\]\n  where M is a high-frequency circular mask (binary), W is a multi-ring key with ring-wise constants sampled from \\(\\mathcal{N}(0,1)\\), and \\(\\odot\\) is elementwise product.\n- Decoupling in DDIM at t* (using Equation (5) derived from PMP):\n  \\[\n  x^{W}_{t^*-1} \\approx \\sqrt{\\alpha_{t^*-1}}\\, f_{\\theta,t^*}(x_{t^*}) + \\sqrt{1-\\alpha_{t^*-1}}\\,\\frac{x_{t^*} + \\lambda \\Delta x - \\sqrt{\\alpha_{t^*}} f_{\\theta,t^*}(x_{t^*})}{\\sqrt{1-\\alpha_{t^*}}}\n  \\]\n  so the watermark affects only the second term (residual path), while the PMP term retains the original prediction.\n- Detection score after inversion to t* (attacked image \\(\\bar{x}^{W}_0\\)):\n  \\[\n  \\bar{x}^{W}_{t^*} := \\mathrm{DDIM\\!-\\!Inv}(\\bar{x}^{W}_0, t^*),\\quad\n  \\eta = \\frac{\\mathrm{sum}(M)\\cdot \\left\\|M\\odot W - M\\odot\\mathrm{DFT}(\\bar{x}^{W}_{t^*})\\right\\|_F^2}{\\left\\|M\\odot\\mathrm{DFT}(\\bar{x}^{W}_{t^*})\\right\\|_F^2}\n  \\]\n  If watermarked, ideally \\(\\eta\\approx 0\\); otherwise \\(\\eta>0\\). Thresholding \\(\\eta<\\eta_0\\) declares watermark presence.\n- Consistency and detectability bounds (sketch):\n  - Consistency (Theorem 1): with \\(\\Delta x\\sim U(\\mathbb{S}^{d-1})\\), Lipschitz \\(L\\), rank \\(r_t\\ll d\\),\n    \\[\n    \\|f_{\\theta,t}(x_t+\\lambda\\Delta x)-f_{\\theta,t}(x_t)\\|_2 \\le \\lambda L\\, h(r_t),\\quad h(r)=\\sqrt{\\frac{r}{d}+\\frac{18\\pi^3}{d-2}\\log(2r)}\n    \\]\n    with probability \\(\\ge 1-1/r_t\\).\n  - Detectability (Theorem 2): one DDIM step + inversion yields\n    \\[\n    \\|\\bar{x}^{W}_t - x^{W}_t\\|_2 \\le \\lambda L\\, h(\\max\\{r_{t-1},r_t\\})\\big[-g(\\alpha_t,\\alpha_{t-1}) + g(\\alpha_{t-1},\\alpha_t)(1-Lg(\\alpha_t,\\alpha_{t-1}))\\big]\n    \\]\n    with probability \\(\\ge 1 - 1/r_t - 1/r_{t-1}\\), where \\(g(x,y)=\\frac{\\sqrt{1-y}\\sqrt{x}-\\sqrt{1-x}\\sqrt{y}}{\\sqrt{1-x}}\\).\n- Complexity:\n  - Watermark synthesis overhead per image: two FFTs and masking \\(O(d\\log d)\\) time, \\(O(d)\\) memory (d = C·H·W latent elements). DDIM/CFG costs remain standard \\(O(S\\cdot \\text{NN})\\), where S is steps and NN denotes one denoiser forward.\n  - Detection overhead: DDIM inversion \\(O(S_{\\text{inv}}\\cdot \\text{NN})\\) plus one FFT and score computation \\(O(d\\log d)\\).\n\nComputational_Properties:\n- Time Complexity:\n  - Server-side generation: unchanged backbone \\(O(S\\cdot \\text{NN})\\) for DDIM/CFG; added watermark FFT/mask cost \\(O(d\\log d)\\) at one timestep t*.\n  - User-side embedding: DDIM inversion to t* and forward to 0 adds \\(O(S_{\\text{inv}}\\cdot \\text{NN} + S_{\\text{for}}\\cdot \\text{NN})\\); watermark FFT \\(O(d\\log d)\\).\n  - Detection: DDIM inversion \\(O(S_{\\text{inv}}\\cdot \\text{NN})\\) + single FFT and score \\(O(d\\log d)\\).\n- Space Complexity:\n  - Storage for M and W: \\(O(d)\\) (mask sparse in frequency domain; practical storage \\(O(|M|)\\)).\n  - Runtime memory dominated by model activations during DDIM/CFG as standard; marginal overhead to hold \\(x_{t^*}\\), its spectrum, and masked spectrum (\\(O(d)\\)).\n- Parallelization:\n  - FFTs are highly parallel and batched across images/channels; elementwise masking is trivially parallel.\n  - DDIM/CFG denoiser calls remain the main parallel workload; no additional synchronization beyond the existing per-step cadence.\n  - Multi-key watermarking uses disjoint masks per key; keys can be embedded/detected in parallel across masks.\n- Hardware Compatibility:\n  - GPU-friendly: cuFFT/FFTW accelerate DFT; mask ops are bandwidth-bound but coalesce well.\n  - CPU feasible for small images; benefits from vectorized FFT. Memory bandwidth is the critical factor for large latent tensors.\n- Training vs. Inference:\n  - Training-free: no additional parameters learned or fine-tuned; works with pretrained diffusion models.\n  - Inference-only overhead consists of FFT + a single add in latent space; detection uses inversion plus FFT.\n- Parameter Count:\n  - No model parameter changes. User-configurable watermark parameters: radius of M, ring layout of W, λ, timestep t*, channel selection c (latent channels).\n- Numerical Stability:\n  - Choose λ to keep spectral modification within high-frequency band energy budget; prevents visible artifacts and avoids saturating activations.\n  - t* selection: mid-range (≈0.2T–0.3T) balances low-rank decoupling with low inversion error; very large t increases DDIM inversion error.\n  - Score normalization in η mitigates scale sensitivity; threshold tuning via ROC ensures stable detection under distortions.\n- Scaling Behavior:\n  - Overhead scales quasi-linearly with latent size via \\(O(d\\log d)\\); independent of number of DDIM steps aside from standard model cost.\n  - Robustness vs. consistency controlled by mask radius and λ: larger masks improve TPR@1%FPR but reduce PSNR/SSIM; curves observed superior to seed-based methods.\n  - Multi-key capability scales with number of disjoint masks; practical robustness remains strong up to 8–16 keys, degrades when masks become too small or overlapping.\n\nImplementation-critical details and pitfalls:\n- Use unshifted DFT to target high-frequency corners; centering (DFT shift) would target low-frequency and increase visible artifacts.\n- Select disjoint masks for multi-key; overlapping masks cause key interference and reduce detection accuracy.\n- In T2I, perform server-side embedding as: \\(x_{t^*}=\\mathrm{CFG}(x_T,t^*,c)\\), inject, then \\(\\mathrm{DDIM}(x^{W}_{t^*},0,\\emptyset)\\); user-side embedding/detection use \\(\\emptyset\\) (empty prompt) for inversion consistency.\n- Prefer embedding in a single latent channel (e.g., c=3) to minimize cross-channel processing distortions; avoid embedding across all channels simultaneously to preserve consistency.",
        "IMPLEMENTATION_GUIDANCE": "Integration_Strategy:\n- Where to integrate\n  - Text-to-image (server scenario, Stable Diffusion/LDMs): modify the sampler loop to inject at an intermediate timestep t*. In HuggingFace diffusers, patch StableDiffusionPipeline (or StableDiffusionXLPipeline) run loop:\n    - Run from step T down to t* using the chosen scheduler (DDIMScheduler recommended).\n    - After obtaining latents at t*, apply watermark injection in latent space: latents_t_star = inject_watermark(latents_t_star, key, mask, lambda).\n    - Resume sampling from t* to 0 as usual.\n  - Image post-processing (user scenario): add a utility that does DDIM inversion to t*, injects watermark, then DDIM forward to 0. In diffusers, create a function shallow_diffuse_embed(image):\n    - Encode image to latents via VAE.encode.\n    - DDIM-Inv for t* steps to get xt*.\n    - inject_watermark at xt*.\n    - DDIM forward from t* to 0 to get xW0 latents; decode with VAE.decode.\n  - Detection: add a detector that\n    - Encodes attacked image to latents (VAE.encode).\n    - DDIM-Inv from 0 to t* (use empty prompt/CFG-uncond branch).\n    - Computes p-value η on the DFT of xt* with the same mask/key.\n- Code-level changes (PyTorch + diffusers)\n  - New module watermarking/shallow_diffuse.py with:\n    - build_mask(shape=(H,W), radius=8, center='fft_unshifted_center'): returns tensor M in [0,1].\n    - sample_key(M, num_rings=6, rng): returns W with ringwise constant values ~ N(0, σw^2).\n    - inject_watermark(x_t, M, W, lam): uses torch.fft.fft2 without fftshift for high-frequency selection:\n      - Xf = torch.fft.fft2(x_t)  # on latents per-channel\n      - Xf_w = Xf*(1-M) + W*M\n      - x_t_w = torch.fft.ifft2(Xf_w).real\n      - return x_t + lam*(x_t_w - x_t)\n    - ddim_inversion(latents, t_star_idx, unet, scheduler, prompt_embeds=None, guidance_scale=0.0): runs inverse steps consistent with DDIM; use scheduler.step with reverse mapping (diffusers’ DDIMScheduler has step + get_scaled_sigma; implement as in community examples for DDIM inversion).\n    - compute_eta(x_t_star_hat, M, W): per Eq. (7) η = sum(M)*||M⊙W - M⊙DFT(x)||_F^2 / ||M⊙DFT(x)||_F^2.\n  - Patch StableDiffusionPipeline.__call__:\n    - If watermark_config is not None:\n      - For server scenario: run the loop until step t*, call inject_watermark, continue.\n    - Expose watermark metadata (t*, lam, mask spec, key hash).\n  - For user scenario, provide ShallowDiffuseEmbedder.embed(image, config) and ShallowDiffuseDetector.detect(image, config).\n- Compatibility\n  - Frameworks: PyTorch 2.1+ (CUDA 11.8+), diffusers >= 0.27, transformers >= 4.40. No custom CUDA kernels required; relies on torch.fft (cuFFT under-the-hood).\n  - Other frameworks (TensorFlow/JAX): mirror API using tf.signal.fft2d/jnp.fft.fft2; mask logic identical.\n- Migration path\n  - From Tree-Ring/RingID server-side methods: remove Fourier noise seeding; instead, inject at intermediate latent xt*. You can keep the DFT mask/key generator (reuse keys, but change from low- to high-frequency mask definition as below).\n  - From non-diffusion watermarking: integrate as a postprocess route by enabling user scenario embedder.\n- Dependencies and hardware\n  - No specialized libraries beyond torch.fft.\n  - Memory/compute overhead is one partial pass to t* (server) or one inversion pass to t* plus forward to 0 (user). See Expected_Outcomes for cost.\n- Training pipeline integration\n  - The method is training-free. For pipelines that fine-tune UNet/VAE, keep watermarking off during training. Enable at inference or data export time only.\n  - For multi-key deployments, provision a key registry (key_id -> mask, W, t*, λ) and store key_id in metadata.\n\nParameter_Settings:\n- Core parameters\n  - T (total inference steps): 25–50 recommended. Works with 10–50; robustness stable, consistency slightly better with ≥25 steps.\n  - t* (embedding timestep index): 0.2T–0.35T; default 0.3T. For T=50, t* = 10–18; default 15.\n  - λ (watermark strength in latent space): 0.25–0.6 for SD 2.1 latents (64×64×4). Default 0.4–0.5.\n    - Increase λ for higher robustness but lower PSNR/SSIM; decrease for better visual fidelity.\n  - Mask M (frequency support):\n    - Domain: unshifted fft (no fftshift).\n    - Shape: circular disk centered at image center (high-frequency region in unshifted layout).\n    - Radius r: 6–10 for 64×64 latents; default r=8. Scale linearly with spatial size (r ≈ 0.125·min(H,W)).\n    - Channel application: single latent channel (c=3 recommended in ablation) or per-channel identical mask. Default: apply to channel index 3 (0-based) only.\n  - Key W:\n    - Construction: multi-ring; K rings (K=6–12). Each ring has constant value sampled from N(0, σw^2), σw=1.0; freeze per key.\n    - Initialization: sample with fixed RNG seed; store key_id and RNG seed; optionally L2-normalize masked W to keep energy consistent across keys.\n- Detection parameters\n  - η threshold (η0): choose to meet target FPR. Calibrate on a held-out set of non-watermarked images: set η0 at 1st percentile of η distribution to achieve ≈1% FPR. Typical η0 falls in 0.005–0.05 depending on λ and r.\n  - Multi-thresholding for robustness reporting: log ROC, AUC, and TPR@1%FPR.\n- CFG and prompts (T2I)\n  - Server scenario: run CFG as usual (guidance_scale ηCFG = 5–9; default 7.5) on steps T→t*, inject, continue CFG to 0.\n  - User scenario: DDIM-Inv with empty prompt (∅) per paper; guidance_scale=0 for inversion and forward embedding to maximize decoupling.\n- Scheduler choice\n  - Prefer DDIMScheduler for both forward and inversion. If using other schedulers, ensure an exact or close inversion is available; inversion error rises with ODE/SDE mismatches.\n- Scale-dependent settings\n  - Larger images (1024×1024, latent 128×128): keep r ≈ 0.125·min(H,W) (e.g., r≈16), λ in 0.2–0.45 (lower λ to keep visual fidelity).\n  - Small models (SD 1.5) vs SD 2.1: similar ranges; verify decoder scaling_factor (commonly 0.18215) and operate on scheduler latents (not pixel space) for consistent behavior.\n- Hardware-dependent settings\n  - Consumer GPUs (RTX 3090/4090, 24 GB): T=30–40 for typical 512×512; t*=0.3T; batch size 1–2 for user scenario inversion+forward. Use fp16; enable xformers/SDPA attention to keep memory < 12 GB.\n  - Data center GPUs (A100 40/80 GB): T=50, batch size 8–16 (server scenario) feasible; negligible overhead.\n- Critical vs robust parameters\n  - Critical: t* selection, scheduler consistency (both directions must match), exact same mask/key in detection, latent scaling correctness.\n  - Robust: number of rings K, σw, single vs per-channel embedding (avoid all-channel embedding which degrades consistency and robustness).\n\nApplication_Conditions:\n- Beneficial scenarios\n  - Need for watermarking both server-side generation and user-side post-processing with one method.\n  - Deployments requiring high visual consistency (PSNR ≥32 on user scenario; ≥35 server) while maintaining strong robustness against distortions and regenerations.\n  - Pipelines based on latent diffusion (Stable Diffusion 1.5/2.1, SDXL) where latent size is modest (64–128).\n- Hardware requirements\n  - Minimum: 12 GB VRAM for 512×512, T ≤ 30 steps (fp16). Recommended: 16–24 GB for T=50 and batch size ≥2.\n  - CPU-only supported but slow; cuFFT accelerates fft2/ifft2 significantly (5–10× faster).\n- Scale considerations\n  - Advantage increases with models whose PMP Jacobian is low-rank in mid timesteps (empirically 0.2T–0.7T). For very small T (≤10), keep t* around 0.2–0.3T to reduce inversion error.\n- Task compatibility\n  - Strong for T2I and unconditional image generation with DDIM-compatible samplers.\n  - Neutral/uncertain for video/audio diffusion without adaptation; temporal consistency and subspace structure differ.\n  - Less suitable for pipelines without an accurate inversion operator (e.g., aggressive stochastic samplers without deterministic counterparts).\n- Choosing over alternatives\n  - Prefer Shallow Diffuse when you need: user-side watermarking, high consistency, independence from initial seed, and no model retraining. Choose Tree-Ring/RingID when only server-side, extreme robustness, and seed access are guaranteed and image consistency is secondary.\n  - Prefer non-diffusion watermarks only when inversion is unavailable and latency must be sub-50 ms without running a diffusion pass.\n- Resource constraints\n  - If compute-limited on edge devices, consider T=25, t*=0.25T. For batch embedding at scale, server-side insertion adds ~0.3T extra forward steps vs. vanilla generation.\n\nExpected_Outcomes:\n- Performance improvements vs baselines\n  - Consistency (User scenario): PSNR ≈ 32±1, SSIM ≈ 0.84–0.89, LPIPS ≈ 0.03–0.05, approaching the upper bound determined by DDIM inversion error (SD w/o WM PSNR ≈ 32–33).\n  - Consistency (Server scenario): PSNR ≈ 35±1, SSIM ≈ 0.95–0.96, LPIPS ≈ 0.02; significantly higher than seed-watermarking methods (Tree-Ring/RingID: PSNR ≈ 10–17).\n  - Robustness: Distortions AUC≈1.00, TPR@1%FPR≈1.00; Regeneration AUC≈0.99–1.00, TPR@1%FPR≈0.93–0.98 (user), 0.98–1.00 (server); Adversarial averaging (BA/GA) TPR@1%FPR≈0.58–0.70 (user), ≈0.45–0.63 (server).\n  - Generation quality (server): CLIP-Score retained vs no-watermark; FID equal/better than other diffusion watermarking baselines.\n- Runtime/latency\n  - Server scenario: negligible net overhead beyond an additional DFT/IDFT at t*; no extra steps. Total generation time roughly unchanged (<3% overhead).\n  - User scenario: requires DDIM-Inv to t* and DDIM forward from t* to 0: ≈ 0.3T + 0.3T = 0.6T additional steps versus no watermark. For T=50, ~30 steps of extra compute; on A100, ~0.3–0.6 s per 512×512 image; on RTX 3090, ~0.7–1.4 s.\n- Trade-offs\n  - Increasing λ or mask radius r improves detection under attacks but reduces PSNR/SSIM. Decreasing t* reduces inversion error (better PSNR) but can slightly reduce robustness if too small (<0.15T).\n  - Embedding across all latent channels increases visibility and reduces robustness; prefer a single channel (e.g., c=3).\n- Failure modes\n  - Inversion mismatch: using a different scheduler or CFG setup in detection than embedding increases η for true positives (missed detections). Always use the same scheduler, t*, and empty prompt for inversion detection.\n  - Extreme compression/cropping or heavy down/up-scaling with non-integer factors may reduce detectability; mitigations: increase λ to 0.55–0.65, enlarge r by 25–50%, or embed multi-key redundantly.\n  - Very small T (≤10) with high t* (≥0.7T) leads to poor inversion accuracy and lower TPR; use t*≤0.35T and/or increase T.\n  - Multi-key large N (≥32) with non-overlapping tiny masks reduces per-key SNR; expect TPR degradation beyond ~16 keys; mitigate by increasing r slightly or using wedge sectors instead of thin rings.\n- Debugging indicators and validation\n  - Sanity checks:\n    - Visual: no structured low-frequency artifacts; LPIPS vs original within 0.03–0.06.\n    - Distribution: η on non-watermarked set forms a tight distribution near 0.03–0.08; watermarked set near 0–0.01 (exact values depend on normalization).\n    - ROC: AUC > 0.98 on clean/distortions.\n  - Implementation validation:\n    - Round-trip xt* consistency: ||DDIM-Inv(DDIM(xt*, t*), t*) − xt*||/||xt*|| < 1e-3.\n    - Watermark decoupling: measure ||pred_x0|| difference at t* with/without λ∆x; should be small and scale with λh(r) (empirically negligible visually).\n    - Seed independence: generate same prompt/seed with two different keys; images should be perceptually identical (PSNR server ≥35).\n- Hardware-specific outcomes\n  - Consumer GPUs with SDPA/xFormers: small additional VRAM (~1–2%) for fft buffers; throughput unchanged for server; user embedding ≈0.6× generation time.\n  - CPU-only: fft dominates; user embedding may be 2–4× slower than GPU; consider server-only usage or batch offloading.\n\nQuality Requirements:\n- Troubleshooting\n  - Watermark not detected (high η for positives):\n    - Verify same t*, scheduler, and guidance settings used for detection (DDIM-Inv with empty prompt).\n    - Confirm mask coordinate convention (unshifted fft) and center location.\n    - Ensure watermark applied in latent space at scheduler scale (not in decoded pixel space).\n    - Increase λ by 0.1 or r by +2; or use multi-rings K+4.\n  - Visible artifacts:\n    - Reduce λ by 0.1; reduce r by 2; ensure only one latent channel is watermarked.\n    - Verify not using fftshift; masking low frequencies will create visible artifacts.\n  - Degraded robustness after resizing/cropping:\n    - Use slightly larger r and multiple non-overlapping mask sectors; enable multi-key redundancy.\n- Validation procedures\n  - Calibrate η0 on 500–1000 non-watermarked images to achieve FPR=1%.\n  - Report PSNR/SSIM/LPIPS against original for both server and user pipelines; target >32 PSNR for user and >35 for server at 512×512.\n  - Attack suite: run JPEG(25), Gaussian blur(ks=7–9), Gaussian noise(σ=0.1), color jitter(brightness up to 6), resize-restore(0.5×), random drop(40%), median blur(ks=7), diffusion purification(0.3T), VAE compression(IC1/IC2), diffusion regeneration, rinsing (2×, 4×), BA/GA averaging. Expect near-perfect detection on all but BA/GA (where TPR@1%FPR ≈0.58–0.70).\n- Risks and limitations\n  - Requires inversion capability and access to the diffusion model (not purely forensic).\n  - Detection depends on secret key and exact mask; key management is essential.\n  - Adversarial averaging attacks remain challenging; multi-key, randomized masks, and slightly higher λ mitigate but do not eliminate risk."
    }
]